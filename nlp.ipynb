{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.24.3\n",
      "Spacy model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import spacy\n",
    "\n",
    "print(f\"Numpy version: {numpy.__version__}\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Spacy model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens and their Parts of Speech:\n",
      "I: PRON (nsubj)\n",
      "want: VERB (ROOT)\n",
      "a: DET (det)\n",
      "red: ADJ (amod)\n",
      "car: NOUN (dobj)\n",
      "that: PRON (nsubj)\n",
      "is: AUX (relcl)\n",
      "fast: ADJ (acomp)\n",
      "and: CCONJ (cc)\n",
      "costs: VERB (conj)\n",
      "less: ADJ (amod)\n",
      "than: ADP (quantmod)\n",
      "100,000: NUM (dobj)\n",
      "$: SYM (punct)\n",
      "\n",
      "Named Entities Detected:\n",
      "less than 100,000$: MONEY\n"
     ]
    }
   ],
   "source": [
    "# Example user input\n",
    "user_input = \"I want a red car that is fast and costs less than 100,000$\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(user_input)\n",
    "\n",
    "# Visualize results\n",
    "print(\"Tokens and their Parts of Speech:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text}: {token.pos_} ({token.dep_})\")\n",
    "\n",
    "print(\"\\nNamed Entities Detected:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For extracting numeric values\n",
    "\n",
    "def extract_car_preferences(user_input):\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    # Initialize filters\n",
    "    preferences = {\n",
    "        \"Make\": None,\n",
    "        \"Color\": None,\n",
    "        \"PriceRange\": None,\n",
    "        \"Mileage\": None,\n",
    "        \"PassengerCapacity\": None,\n",
    "        \"BodyType\": None,\n",
    "    }\n",
    "\n",
    "    # Extract named entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"MONEY\":\n",
    "            # Handle price range (e.g., \"under $30,000\")\n",
    "            if \"under\" in user_input:\n",
    "                preferences[\"PriceRange\"] = f\"<= {ent.text.replace('$', '').replace(',', '')}\"\n",
    "            elif \"over\" in user_input:\n",
    "                preferences[\"PriceRange\"] = f\">= {ent.text.replace('$', '').replace(',', '')}\"\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            # Extract Make (e.g., \"Toyota\")\n",
    "            preferences[\"Make\"] = ent.text\n",
    "        elif ent.label_ == \"CARDINAL\":\n",
    "            # Handle number of passengers or mileage\n",
    "            # Use regex to extract numeric values\n",
    "            match = re.search(r\"\\d+\", ent.text)\n",
    "            if match:\n",
    "                number = int(match.group())\n",
    "                if \"seats\" in user_input or \"passengers\" in user_input:\n",
    "                    preferences[\"PassengerCapacity\"] = number\n",
    "                elif \"miles\" in user_input or \"mileage\" in user_input:\n",
    "                    preferences[\"Mileage\"] = f\"<= {number}\"\n",
    "\n",
    "    # Extract adjectives for color or style\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            if token.text in [\"red\", \"blue\", \"black\", \"white\", \"green\"]:  # Expand with more colors\n",
    "                preferences[\"Color\"] = token.text\n",
    "            elif token.text in [\"SUV\", \"sedan\", \"truck\"]:  # Body type\n",
    "                preferences[\"BodyType\"] = token.text\n",
    "\n",
    "    return preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Make': 'Toyota', 'Color': 'red', 'PriceRange': '<= 30000', 'Mileage': None, 'PassengerCapacity': 5, 'BodyType': None}\n"
     ]
    }
   ],
   "source": [
    "preferences = extract_car_preferences(\"I want a red Toyota SUV under $30,000 with at least 5 seats.\")\n",
    "print(preferences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Make': 'Toyota', 'Color': None, 'PriceRange': '<= 30000', 'Mileage': None, 'PassengerCapacity': 5, 'BodyType': None}\n"
     ]
    }
   ],
   "source": [
    "preferences = extract_car_preferences(\"I want a Toyota SUV under $30,000 with at least 5 seats.\")\n",
    "print(preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Make': None, 'Color': 'green', 'PriceRange': None, 'Mileage': '<= 50', 'PassengerCapacity': None, 'BodyType': None}\n"
     ]
    }
   ],
   "source": [
    "preferences = extract_car_preferences(\"I'm looking for a big car, around 30,000$, with less than 50,000km in mileage, a green car.\")\n",
    "print(preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary of target fields with representative words\n",
    "context_keywords = {\n",
    "    \"PassengerCapacity\": [\"seats\", \"passengers\", \"people\"],\n",
    "    \"Mileage\": [\"mileage\", \"miles\", \"distance\"],\n",
    "    \"PriceRange\": [\"cost\", \"budget\", \"price\", \"under\", \"over\"],\n",
    "    \"Color\": [\"color\", \"shade\", \"red\", \"blue\", \"black\"],\n",
    "    \"BodyType\": [\"SUV\", \"truck\", \"sedan\", \"convertible\"]\n",
    "}\n",
    "\n",
    "def match_field_by_context(word):\n",
    "    for field, keywords in context_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            # Compare semantic similarity\n",
    "            if nlp(word).similarity(nlp(keyword)) > 0.7:  # Adjust threshold as needed\n",
    "                return field\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_input(user_input):\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    # Try semantic matching\n",
    "    preferences = {}\n",
    "    for token in doc:\n",
    "        matched_field = match_field_by_context(token.text)\n",
    "        if matched_field:\n",
    "            preferences[matched_field] = token.text\n",
    "\n",
    "    # Fallback to rules for entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"MONEY\":\n",
    "            preferences[\"PriceRange\"] = ent.text.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "\n",
    "    return preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\722602574.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  if nlp(word).similarity(nlp(keyword)) > 0.7:  # Adjust threshold as needed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Color': 'red',\n",
       " 'Mileage': 'car',\n",
       " 'PassengerCapacity': 'costs',\n",
       " 'PriceRange': 'less than 100000'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_input(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\1570112413.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"people\").similarity(nlp(\"zebras\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.663036879335241"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"people\").similarity(nlp(\"zebras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_contextual_filters(user_input):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant for car recommendations.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define feature mappings\n",
    "FEATURES = {\n",
    "    \"BodyType\": [\"SUV\", \"sedan\", \"convertible\", \"truck\", \"hatchback\", \"luxury\", \"big\", \"family\", \"compact\"],\n",
    "    \"Color\": [\"red\", \"blue\", \"black\", \"white\", \"green\", \"yellow\", \"dark\", \"bright\"],\n",
    "    \"PriceRange\": [\"cheap\", \"affordable\", \"expensive\", \"high end\", \"luxury\", \"under\", \"over\", \"less\", \"more\"],\n",
    "    \"Mileage\": [\"mileage\", \"miles\", \"distance\"],\n",
    "    \"PassengerCapacity\": [\"seats\", \"passengers\", \"people\", \"family\", \"room\"],\n",
    "    \"Condition\": [\"used\", \"new\", \"pre-owned\", \"certified\"],\n",
    "    \"Make\": [\"Ferrari\", \"Toyota\", \"Honda\", \"Ford\", \"BMW\", \"Mercedes\", \"Tesla\"],\n",
    "    \"Sustainability\": [\"electric\", \"hybrid\", \"sustainable\", \"eco-friendly\", \"green\"],\n",
    "    \"Safety\": [\"safe\", \"reliable\", \"sturdy\", \"secure\"],\n",
    "}\n",
    "\n",
    "\n",
    "def extract_features(user_input):\n",
    "    doc = nlp(user_input)\n",
    "    \n",
    "    # Initialize extracted features\n",
    "    extracted = {\n",
    "        \"Make\": None,\n",
    "        \"Color\": [],\n",
    "        \"PriceRange\": None,\n",
    "        \"Mileage\": None,\n",
    "        \"BodyType\": None,\n",
    "        \"PassengerCapacity\": None,\n",
    "        \"Condition\": None,\n",
    "        \"Sustainability\": None,\n",
    "        \"Safety\": None,\n",
    "    }\n",
    "\n",
    "    # Extract entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"MONEY\":\n",
    "            extracted[\"PriceRange\"] = ent.text\n",
    "        elif ent.label_ == \"CARDINAL\" or ent.label_ == \"QUANTITY\":\n",
    "            if \"miles\" in user_input:\n",
    "                extracted[\"Mileage\"] = ent.text\n",
    "            elif \"seats\" in user_input or \"passengers\" in user_input:\n",
    "                extracted[\"PassengerCapacity\"] = ent.text\n",
    "\n",
    "    # Match keywords\n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "        for feature, keywords in FEATURES.items():\n",
    "            if word in keywords:\n",
    "                if feature == \"Color\":\n",
    "                    extracted[feature].append(word)  # Allow multiple colors\n",
    "                else:\n",
    "                    extracted[feature] = word\n",
    "    \n",
    "    # Clean up results\n",
    "    extracted[\"Color\"] = list(set(extracted[\"Color\"]))  # Remove duplicates\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I'm looking for a big car, red or blue, under 40k $ and lower than 50,000 miles.\n",
      "Extracted Features: {'Make': None, 'Color': ['red', 'blue'], 'PriceRange': 'under', 'Mileage': 'miles', 'BodyType': 'big', 'PassengerCapacity': None, 'Condition': None, 'Sustainability': None, 'Safety': None}\n",
      "--------------------------------------------------\n",
      "Input: Do you have a Ferrari, used.\n",
      "Extracted Features: {'Make': None, 'Color': [], 'PriceRange': None, 'Mileage': None, 'BodyType': None, 'PassengerCapacity': None, 'Condition': 'used', 'Sustainability': None, 'Safety': None}\n",
      "--------------------------------------------------\n",
      "Input: I want a cheap fast car for less than 90000.\n",
      "Extracted Features: {'Make': None, 'Color': [], 'PriceRange': 'less', 'Mileage': None, 'BodyType': None, 'PassengerCapacity': None, 'Condition': None, 'Sustainability': None, 'Safety': None}\n",
      "--------------------------------------------------\n",
      "Input: Give me a high end luxury SUV for me and my family.\n",
      "Extracted Features: {'Make': None, 'Color': [], 'PriceRange': 'luxury', 'Mileage': None, 'BodyType': 'family', 'PassengerCapacity': 'family', 'Condition': None, 'Sustainability': None, 'Safety': None}\n",
      "--------------------------------------------------\n",
      "Input: Suggest a safe car, affordable, sustainable car, in dark colors.\n",
      "Extracted Features: {'Make': None, 'Color': ['dark'], 'PriceRange': 'affordable', 'Mileage': None, 'BodyType': None, 'PassengerCapacity': None, 'Condition': None, 'Sustainability': 'sustainable', 'Safety': 'safe'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"I'm looking for a big car, red or blue, under 40k $ and lower than 50,000 miles.\",\n",
    "    \"Do you have a Ferrari, used.\",\n",
    "    \"I want a cheap fast car for less than 90000.\",\n",
    "    \"Give me a high end luxury SUV for me and my family.\",\n",
    "    \"Suggest a safe car, affordable, sustainable car, in dark colors.\",\n",
    "]\n",
    "\n",
    "for inp in inputs:\n",
    "    print(f\"Input: {inp}\")\n",
    "    features = extract_features(inp)\n",
    "    print(f\"Extracted Features: {features}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    \"BodyType\": {\n",
    "        \"keywords\": [\"SUV\", \"sedan\", \"big\",\"Small\"],\n",
    "        \"implications\": {\"big\": [\"SUV\", \"4x4\"], \"Small\": [\"sedan\"]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_feature_by_similarity(word, feature_category):\n",
    "    \"\"\"\n",
    "    Match a word to a feature category using semantic similarity.\n",
    "    \"\"\"\n",
    "    doc_word = nlp(word)\n",
    "    best_match = None\n",
    "    best_score = 0.7  # Threshold for similarity\n",
    "    for keyword in FEATURES[feature_category][\"keywords\"]:\n",
    "        similarity = doc_word.similarity(nlp(keyword))\n",
    "        if similarity > best_score:\n",
    "            best_match = keyword\n",
    "            best_score = similarity\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I'm looking for a big car.\n",
      "Extracted BodyType: ['4x4', 'SUV']\n",
      "--------------------------------------------------\n",
      "Input: I want a small vehicle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\814533289.py:46: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = doc_word.similarity(nlp(normalized_keyword))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted BodyType: ['Small', 'SUV']\n",
      "--------------------------------------------------\n",
      "Input: Do you have any SUVs?\n",
      "Extracted BodyType: ['SUV']\n",
      "--------------------------------------------------\n",
      "Input: Suggest a sedans for me.\n",
      "Extracted BodyType: ['sedan']\n",
      "--------------------------------------------------\n",
      "Input: Is there a big 4x4 available?\n",
      "Extracted BodyType: ['4x4', 'SUV']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import inflect  # For singular/plural normalization\n",
    "from rapidfuzz import fuzz  # For fuzzy matching\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "p = inflect.engine()  # Inflect engine for singular/plural normalization\n",
    "\n",
    "# Define the feature for BodyType\n",
    "FEATURES = {\n",
    "    \"BodyType\": {\n",
    "        \"keywords\": [\"SUV\", \"sedan\", \"big\", \"small\"],\n",
    "        \"implications\": {\"big\": [\"SUV\", \"4x4\"], \"small\": [\"sedan\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "def normalize_word(word):\n",
    "    \"\"\"\n",
    "    Normalize the word for comparison (lowercase, singular form).\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    word = p.singular_noun(word) if p.singular_noun(word) else word  # Convert to singular if plural\n",
    "    return word\n",
    "\n",
    "def fuzzy_match(word, keyword_list, threshold=85):\n",
    "    \"\"\"\n",
    "    Fuzzy match a word against a list of keywords.\n",
    "    \"\"\"\n",
    "    for keyword in keyword_list:\n",
    "        if fuzz.ratio(word, keyword.lower()) >= threshold:\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "def match_feature_by_similarity(word, feature_category):\n",
    "    \"\"\"\n",
    "    Match a word to a feature category using semantic similarity and fuzzy matching.\n",
    "    \"\"\"\n",
    "    doc_word = nlp(normalize_word(word))  # Normalize the word\n",
    "    best_match = None\n",
    "    best_score = 0.7  # Threshold for spaCy similarity\n",
    "    for keyword in FEATURES[feature_category][\"keywords\"]:\n",
    "        # Normalize keyword\n",
    "        normalized_keyword = normalize_word(keyword)\n",
    "        \n",
    "        # Check similarity using spaCy\n",
    "        similarity = doc_word.similarity(nlp(normalized_keyword))\n",
    "        if similarity > best_score:\n",
    "            best_match = keyword\n",
    "            best_score = similarity\n",
    "        \n",
    "        # Check fuzzy match if similarity fails\n",
    "        if not best_match:\n",
    "            fuzzy_matched = fuzzy_match(word, FEATURES[feature_category][\"keywords\"])\n",
    "            if fuzzy_matched:\n",
    "                best_match = fuzzy_matched\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def extract_body_type(user_input):\n",
    "    \"\"\"\n",
    "    Extract BodyType feature from user input.\n",
    "    \"\"\"\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    # Initialize extracted BodyType and implication flag\n",
    "    extracted_body_type = []\n",
    "    implication_applied = False\n",
    "\n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "\n",
    "        # Apply implications for descriptive words first\n",
    "        if word in FEATURES[\"BodyType\"][\"implications\"]:\n",
    "            extracted_body_type.extend(FEATURES[\"BodyType\"][\"implications\"][word])\n",
    "            implication_applied = True\n",
    "\n",
    "        # Match BodyType keywords only if no implication has been applied\n",
    "        elif not implication_applied:\n",
    "            body_type = match_feature_by_similarity(word, \"BodyType\")\n",
    "            if body_type:\n",
    "                extracted_body_type.append(body_type)\n",
    "\n",
    "    # Remove duplicates and return\n",
    "    return list(set(extracted_body_type))\n",
    "\n",
    "# Test the function with inputs\n",
    "inputs = [\n",
    "    \"I'm looking for a big car.\",\n",
    "    \"I want a small vehicle.\",\n",
    "    \"Do you have any SUVs?\",\n",
    "    \"Suggest a sedans for me.\",\n",
    "    \"Is there a big 4x4 available?\"\n",
    "]\n",
    "\n",
    "for inp in inputs:\n",
    "    print(f\"Input: {inp}\")\n",
    "    body_type = extract_body_type(inp)\n",
    "    print(f\"Extracted BodyType: {body_type}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I'm looking for a car under $40,000.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: I want a vehicle less than 50k.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: Show me cars over $20,000.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: Do you have any cars between $10,000 and $30,000?\n",
      "Extracted Price Range: {'min': 10000, 'max': 30000}\n",
      "--------------------------------------------------\n",
      "Input: I want a car above 60k.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: Cars greater than $15,000.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: Find me a car that's over 25k but less than 75k.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: I need an SUV cheaper than $35,000.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n",
      "Input: I want something priced around 50k.\n",
      "Extracted Price Range: {'min': None, 'max': None}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\868320754.py:25: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  max_similarity = token.similarity(REFERENCE_TERMS[\"max\"])\n",
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\868320754.py:26: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  min_similarity = token.similarity(REFERENCE_TERMS[\"min\"])\n",
      "C:\\Users\\karim\\AppData\\Local\\Temp\\ipykernel_23144\\868320754.py:27: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  range_similarity = token.similarity(REFERENCE_TERMS[\"range\"])\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Budget-related reference terms for semantic matching\n",
    "REFERENCE_TERMS = {\n",
    "    \"max\": nlp(\"less than\"),\n",
    "    \"min\": nlp(\"more than\"),\n",
    "    \"range\": nlp(\"between\")\n",
    "}\n",
    "\n",
    "def parse_price(price_str):\n",
    "    \"\"\"Convert price strings to integers.\"\"\"\n",
    "    try:\n",
    "        return int(price_str.replace(\"$\", \"\").replace(\",\", \"\").replace(\"k\", \"000\"))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def determine_budget_context(token):\n",
    "    \"\"\"\n",
    "    Determine if a token represents a budget context\n",
    "    using semantic similarity with predefined references.\n",
    "    \"\"\"\n",
    "    max_similarity = token.similarity(REFERENCE_TERMS[\"max\"])\n",
    "    min_similarity = token.similarity(REFERENCE_TERMS[\"min\"])\n",
    "    range_similarity = token.similarity(REFERENCE_TERMS[\"range\"])\n",
    "\n",
    "    if max_similarity > 0.7:\n",
    "        return \"max\"\n",
    "    elif min_similarity > 0.7:\n",
    "        return \"min\"\n",
    "    elif range_similarity > 0.7:\n",
    "        return \"range\"\n",
    "    return None\n",
    "\n",
    "def extract_price_range_dynamic(user_input):\n",
    "    \"\"\"\n",
    "    Extract price range from user input using semantic similarity and dynamic parsing.\n",
    "    \"\"\"\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    # Initialize price range\n",
    "    price_range = {\"min\": None, \"max\": None}\n",
    "\n",
    "    # Extract potential prices and their contexts\n",
    "    prices = []\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in {\"MONEY\", \"CARDINAL\"} or \"k\" in token.text.lower():\n",
    "            price = parse_price(token.text)\n",
    "            if price:\n",
    "                prices.append((price, token))\n",
    "\n",
    "    for price, token in prices:\n",
    "        # Determine the context of the price\n",
    "        context = determine_budget_context(token.head)\n",
    "        if context == \"max\":\n",
    "            price_range[\"max\"] = price\n",
    "        elif context == \"min\":\n",
    "            price_range[\"min\"] = price\n",
    "        elif context == \"range\" and len(prices) >= 2:\n",
    "            sorted_prices = sorted([p[0] for p in prices])\n",
    "            price_range[\"min\"], price_range[\"max\"] = sorted_prices[0], sorted_prices[1]\n",
    "\n",
    "    # Ensure logical consistency\n",
    "    if price_range[\"min\"] and price_range[\"max\"] and price_range[\"min\"] > price_range[\"max\"]:\n",
    "        price_range[\"min\"], price_range[\"max\"] = price_range[\"max\"], price_range[\"min\"]\n",
    "\n",
    "    return price_range\n",
    "\n",
    "# Test the function with various inputs\n",
    "inputs = [\n",
    "    \"I'm looking for a car under $40,000.\",\n",
    "    \"I want a vehicle less than 50k.\",\n",
    "    \"Show me cars over $20,000.\",\n",
    "    \"Do you have any cars between $10,000 and $30,000?\",\n",
    "    \"I want a car above 60k.\",\n",
    "    \"Cars greater than $15,000.\",\n",
    "    \"Find me a car that's over 25k but less than 75k.\",\n",
    "    \"I need an SUV cheaper than $35,000.\",\n",
    "    \"I want something priced around 50k.\",\n",
    "]\n",
    "\n",
    "for inp in inputs:\n",
    "    print(f\"Input: {inp}\")\n",
    "    price_range = extract_price_range_dynamic(inp)\n",
    "    print(f\"Extracted Price Range: {price_range}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model for question answering\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m qa_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion-answering\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistilbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_budget_using_qa\u001b[39m(input_text):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Use a QA model to extract budget-related information dynamically.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:926\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    925\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 926\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    927\u001b[0m         model,\n\u001b[0;32m    928\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    929\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    930\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    931\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    934\u001b[0m     )\n\u001b[0;32m    936\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    937\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\base.py:240\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    246\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained model for question answering\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased\")\n",
    "\n",
    "def extract_budget_using_qa(input_text):\n",
    "    \"\"\"\n",
    "    Use a QA model to extract budget-related information dynamically.\n",
    "    \"\"\"\n",
    "    questions = [\n",
    "        \"What is the maximum budget?\",\n",
    "        \"What is the minimum budget?\",\n",
    "        \"Are there any price ranges mentioned?\",\n",
    "    ]\n",
    "\n",
    "    # Extract answers for budget-related questions\n",
    "    extracted_info = {}\n",
    "    for question in questions:\n",
    "        answer = qa_pipeline(question=question, context=input_text)\n",
    "        if answer[\"score\"] > 0.5:  # Confidence threshold\n",
    "            extracted_info[question] = answer[\"answer\"]\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "# Test inputs\n",
    "inputs = [\n",
    "    \"I'm looking for a car under $40,000.\",\n",
    "    \"Show me cars over $20,000.\",\n",
    "    \"Do you have any cars between $10,000 and $30,000?\",\n",
    "    \"Find me a cheap car.\",\n",
    "    \"I want a car above 60k.\",\n",
    "]\n",
    "\n",
    "for inp in inputs:\n",
    "    print(f\"Input: {inp}\")\n",
    "    extracted = extract_budget_using_qa(inp)\n",
    "    print(f\"Extracted Info: {extracted}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\Scripts\\python.exe\n",
      "C:\\Users\\karim\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\numpy\\_typing\\_scalars.py:12: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  _BoolLike_co = Union[bool, np.bool]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     47\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\numpy\\typing\\__init__.py:158\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m============================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTyping (:mod:`numpy.typing`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# NOTE: The API section will be appended with additional entries\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# further down in this file\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    159\u001b[0m     ArrayLike,\n\u001b[0;32m    160\u001b[0m     DTypeLike,\n\u001b[0;32m    161\u001b[0m     NBitBase,\n\u001b[0;32m    162\u001b[0m     NDArray,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    165\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrayLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBitBase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDArray\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\numpy\\_typing\\__init__.py:151\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nbit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     96\u001b[0m     _NBitByte \u001b[38;5;28;01mas\u001b[39;00m _NBitByte,\n\u001b[0;32m     97\u001b[0m     _NBitShort \u001b[38;5;28;01mas\u001b[39;00m _NBitShort,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     _NBitLongDouble \u001b[38;5;28;01mas\u001b[39;00m _NBitLongDouble,\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_char_codes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    109\u001b[0m     _BoolCodes \u001b[38;5;28;01mas\u001b[39;00m _BoolCodes,\n\u001b[0;32m    110\u001b[0m     _UInt8Codes \u001b[38;5;28;01mas\u001b[39;00m _UInt8Codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     _ObjectCodes \u001b[38;5;28;01mas\u001b[39;00m _ObjectCodes,\n\u001b[0;32m    150\u001b[0m )\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scalars\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    152\u001b[0m     _CharLike_co \u001b[38;5;28;01mas\u001b[39;00m _CharLike_co,\n\u001b[0;32m    153\u001b[0m     _BoolLike_co \u001b[38;5;28;01mas\u001b[39;00m _BoolLike_co,\n\u001b[0;32m    154\u001b[0m     _UIntLike_co \u001b[38;5;28;01mas\u001b[39;00m _UIntLike_co,\n\u001b[0;32m    155\u001b[0m     _IntLike_co \u001b[38;5;28;01mas\u001b[39;00m _IntLike_co,\n\u001b[0;32m    156\u001b[0m     _FloatLike_co \u001b[38;5;28;01mas\u001b[39;00m _FloatLike_co,\n\u001b[0;32m    157\u001b[0m     _ComplexLike_co \u001b[38;5;28;01mas\u001b[39;00m _ComplexLike_co,\n\u001b[0;32m    158\u001b[0m     _TD64Like_co \u001b[38;5;28;01mas\u001b[39;00m _TD64Like_co,\n\u001b[0;32m    159\u001b[0m     _NumberLike_co \u001b[38;5;28;01mas\u001b[39;00m _NumberLike_co,\n\u001b[0;32m    160\u001b[0m     _ScalarLike_co \u001b[38;5;28;01mas\u001b[39;00m _ScalarLike_co,\n\u001b[0;32m    161\u001b[0m     _VoidLike_co \u001b[38;5;28;01mas\u001b[39;00m _VoidLike_co,\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    164\u001b[0m     _Shape \u001b[38;5;28;01mas\u001b[39;00m _Shape,\n\u001b[0;32m    165\u001b[0m     _ShapeLike \u001b[38;5;28;01mas\u001b[39;00m _ShapeLike,\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dtype_like\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    168\u001b[0m     DTypeLike \u001b[38;5;28;01mas\u001b[39;00m DTypeLike,\n\u001b[0;32m    169\u001b[0m     _DTypeLike \u001b[38;5;28;01mas\u001b[39;00m _DTypeLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m     _DTypeLikeComplex_co \u001b[38;5;28;01mas\u001b[39;00m _DTypeLikeComplex_co,\n\u001b[0;32m    184\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\numpy\\_typing\\_scalars.py:12\u001b[0m\n\u001b[0;32m      8\u001b[0m _CharLike_co \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# The 6 `<X>Like_co` type-aliases below represent all scalars that can be\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# coerced into `<X>` (with the casting rule `same_kind`)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m _BoolLike_co \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mbool\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m]\n\u001b[0;32m     13\u001b[0m _UIntLike_co \u001b[38;5;241m=\u001b[39m Union[_BoolLike_co, np\u001b[38;5;241m.\u001b[39munsignedinteger[Any]]\n\u001b[0;32m     14\u001b[0m _IntLike_co \u001b[38;5;241m=\u001b[39m Union[_BoolLike_co, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger[Any]]\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Available: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, is_tf_available\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow Available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_tf_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m qa_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion-answering\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistilbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:926\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    925\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 926\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    927\u001b[0m         model,\n\u001b[0;32m    928\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    929\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    930\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    931\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    934\u001b[0m     )\n\u001b[0;32m    936\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    937\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\base.py:240\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    246\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, is_tf_available\n",
    "\n",
    "print(f\"TensorFlow Available: {is_tf_available()}\")\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased\", framework=\"tf\")\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "NumPy version: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())  # Check if CUDA is built-in (optional for CPU)\n",
    "print(tf.config.list_physical_devices())  # List available devices (CPU/GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Available in Hugging Face: False\n"
     ]
    }
   ],
   "source": [
    "from transformers import is_tf_available\n",
    "print(f\"TensorFlow Available in Hugging Face: {is_tf_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Is TensorFlow available: {tf.test.is_built_with_cuda()}\")\n",
    "print(f\"Available devices: {tf.config.list_physical_devices()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Available in Hugging Face: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow Available in Hugging Face: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_tf_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Explicitly set the framework\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m qa_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion-answering\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistilbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:926\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    925\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 926\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    927\u001b[0m         model,\n\u001b[0;32m    928\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    929\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    930\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    931\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    932\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    934\u001b[0m     )\n\u001b[0;32m    936\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    937\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\karim\\OneDrive\\Desktop\\CODEJAM14Repo\\CodeJam14KKSB\\venv\\lib\\site-packages\\transformers\\pipelines\\base.py:240\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    246\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import pipeline, is_tf_available\n",
    "\n",
    "print(f\"TensorFlow Available in Hugging Face: {is_tf_available()}\")\n",
    "\n",
    "# Explicitly set the framework\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased\", framework=\"tf\")\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
